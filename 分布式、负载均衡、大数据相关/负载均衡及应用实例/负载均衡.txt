负载均衡：
    负载：就是后端系统的承载能力。比如同等条件下，一个1核cpu-1G内存的机器的承载能力一般会比
          8核cpu-8G内存的机器要差；相同配置下，一个cpu利用率为80%的机器比30%的承载能力一般要
          差等等。
    均衡：保证后端请求的平衡。比如：在同等情况下，分配到多台机器的请求要相当；有些情况下，同
          一用户尽可能分配到同一台机器等等。

负载均衡的算法实际上就是解决跨系统调用的时候，在考虑后端机器承载情况的前提下，保证请求分配的
平衡和合理。

负载算法：
    A、简单粗暴有效的：手工配置！
大家是不是觉得这个听起来很山寨呢？其实不是。这种方式对于中小系统来讲是最有效最稳定的。
因为后端机器的性能配置、上面部署了哪些服务、还能有多大的承载能力等等，我们是最清楚的。
那我们在配置的时候，就可以明确的告诉调用者，你只能分配多大的压力到某台服务器上，多了不行！
例如：我们经常看到nginx的配置：

upstream simplemain.com {

     server  192.168.1.100:8080 weight=30;

     server  192.168.1.101:8080 weight=70;

}
就是说，虽然有两台后端的服务器，但是他们承载能力是不一样的，有一个能力更强，我们就给他70%的压力；
有一个更弱，我们就给他30%的压力。这样，nginx就会把更多的压力分配给第二台。这种方式配置简单，
而且很稳定，基本不会产生分配的抖动。不过，带来的问题就是分配很固定，不能动态调整。
如果你的后端服务器有一段时间出现性能抖动（比如有其他服务扰动了机器的稳定运行，造成cpu利用率一段时间升高），
前端调用者就很难根据实际的情况重新分配请求压力。所以，引入了第二种方法。
   B、动态调整。
这种方案会根据机器当前运行的状态和历史平均值进行对比，发现如果当前状态比历史的要糟糕，那么就
动态减少请求的数量。如果比历史的要好，那么就可以继续增加请求的压力，直到达到一个平衡。
具体怎么做呢？
   首先，刚开始接入的时候，我们可以计算所有机器对于请求的响应时间，算一个平均值。对于响应较快的机
器，我们可以多分配一些请求。如果请求多了导致响应减慢，这个时候就会逐步和其他机器持平，说明这台
机器达到了相应的平衡。
接着，当接入达到平衡以后，就可以统计这台机器平均的响应时间。如果某一段响应请求变慢了（同时比其
他机器都要慢），就可以减少对他请求的分配，将压力转移一部分到其他机器，直到所有机器达到一个整体
的平衡。
   这种方案是不是看起来很高级呢？他的好处在于可以动态的来平衡后面服务器的处理能力。不过，任何事物
都有两面性。这种方案如果遇到极端情况，可能会造成系统雪崩！当某台机器出现短暂网络抖动的时候，他
的响应就可能变慢，这个时候，前端服务就会将他的请求分配给其他的机器。如果分配的很多，就有可能造
成某些机器响应也变慢。然后又将这些机器的请求分配给另外的……如此这般，那些勤勤恳恳的机器终将被
这些请求压死。
   所以，更好的方案，将两者结合。一方面静态配置好承载负荷的一个范围，超过最大的就扔掉；另一方面动态的监控后端机器的响应情况，做小范围的请求调整。




均衡算法：均衡算法主要解决将请求如何发送给后端服务。经常会用到以下四种算法：随机（random）、轮询及加权轮询（round-robin）、一致哈希（consistent-hash）和最小连接及加权最小连接。

1.随机算法（最常用的）
  就是在选取后端服务器的时候，采用随机的一个方法。
  例如我们有两台机器，分别需要承载30%和70%的压力，那么我们算法就可以这样来写（伪代码）：
bool res = abs(rand()) % 100 < 30
这句话是什么意思呢？
1）我们先产生一个伪随机数：rand()
2）将这个伪随机数的转化为非负数: abs(rand())
3）将这个数取模100，将值转化到[0,100)的半开半闭区间：abs(rand()) % 100
4）看这个数是否落入了前30个数的区间[0,30)：abs(rand()) % 100 < 30
如果随机是均匀的话，他们落到[0,100)这个区间里一定是均匀的，所以只要在[0,30)这个区间里，我们就分给第一台机器，否则就分给第二台机器。
特点：首先，从概率上讲，它能保证我们的请求基本是分散的，从而达到我们想要的均衡效果；其次，他
又是无状态的，不需要维持上一次的选择状态，也不需要均衡因子等等。总体上，方便实惠又好用，我们
一直用他！

2.轮询算法
轮训算法就像是挨个数数一样（123-123-123……），一个个的轮着来。
例如还是这个配置，我们就可以这样来做（为了方便，我们把第一台机器叫做A，第二台叫做B）：
1）我们先给两台机器做个排序的数组：array = [ABBABBABBB]
2）我们用一个计数指针来标明现在数组的位置：idx = 3
3）当一个请求来的时候，我们就把指针对应的机器选取出来，并且指针加一，挪到下一个位置。
这样，十个请求，我们就可以保证有3个一定是A，7个一定是B。
轮训算法在实际中也有使用，但是因为要维护idx指针，所以是有状态的。我们经常会用随机算法取代。

3.一致性Hash算法
   主题思想：一般都会讲将[0,232)所有的整数投射到一个圆上，然后再将你的机器的唯一编码（比如：IP）通
过hash运算得到的整数也投射到这个圆上（Node-A、Node-B）。如果一个请求来了，就将这个请求的唯一编码（比如：用户id）
通过hash算法运算得到的整数也投射到这个圆上（request-1、request-2），通过顺时针方向，找到第一个对应的机器。
   一致Hash要解决的是两个问题：
1）散列的不变性：就是同一个请求（比如：同一个用户id）尽量的落入到一台机器，不要因为时间等其他原因，
落入到不同的机器上了；
2）异常以后的分散性：当某些机器坏掉（或者增加机器），原来落到同一台机器的请求（比如：用户id为1，101，201），
尽量分散到其他机器，不要都落入其他某一台机器。这样对于系统的冲击和影响最小。

4.最小连接及加权最小连接
    最少连接(Least Connections)在多个服务器中，与处理连接数(会话数)最少的服务器进行通信的算法。即使
在每台服务器处理能力各不相同，每笔业务处理量也不相同的情况下，也能够在一定程度上降低服务器的负载。
    加权最少连接(Weighted Least Connection)为最少连接算法中的每台服务器附加权重的算法，该算法事先为每
台服务器分配处理连接的数量，并将客户端请求转至连接数最少的服务器上。


