1.抢占式内核与非抢占式内核的特点与区别
1）非抢占式内核是由任务主动放弃CPU的使用权。非抢占式调度法也称为合作型多任务，各个任务彼此共享一个CPU。异步事件由中断服务处理。中断服务可以使一个高优先级的任务
由挂起状态转为就绪状态。但中断服务以后的控制权还是回到原来被中断了的那个任务，直到该任务主动放弃CPU的使用权时，那个高优先级的任务才能获得CPU的使用权。
   非抢占式内核的优点：
   i.中断响应快（与抢占式内核相比）；
   ii.允许使用不可重入函数；
   iii.几乎不需要使用信号量保护共享数据。运行的任务占有CPU，不必担心被其他任务抢占。
   非抢占式内核的缺点：
   i.任务相应时间慢。高优先级的任务已经进入就绪态，但还不能运行，要等到当前运行着的任务释放CPU后才能进行任务执行。
   ii.非抢占式内核的任务级响应时间是不确定的，最高优先级的任务获得CPU的控制权的时间，完全取决于已经运行进程何时释放CPU。
2）使用抢占式内核可以保障系统响应时间。最高优先级的任务一旦就绪，总能得到CPU的使用权。当一个运行着的任务使一个比它优先级高的任务进入了就绪态，当前任务的CPU使
用权就会被剥夺，或者说被挂起了，那个高优先级的任务便会立刻得到CPU的控制权。如果是中断服务子程序使一个高优先级的任务进入就绪状态，中断完成时，中断了的任务就会
被挂起，优先级高的任务便开始控制CPU。
   抢占式内核的优点：
   i.使用抢占式内核，最高优先级的任务能够得到最快程度的相应，高优先级任务肯定能够获得CPU使用权。抢占式内核使得任务优先级相应时间机制得以最优化。
   ii.使内核可抢占的目的是减少用户态进程的分派延迟（dispatch latency），即从进程变为可执行状态到它实际开始运行之间的时间间隔。内核抢占对执行及时被调度的任务
   （如硬件控制器，环境监视器，电影播放器等）的进程确实是由好处的，因为它降低了这种进程被另一个运行在内核态的进程延迟的风险。
   抢占式内核的缺点：
   i.不能直接使用不可重入型函数。调用不可重入函数时，要满足互斥条件，可以使用互斥性信号量来实现。如果调用不可重入型函数时，对于低优先级的任务，其CPU使用权会
   被高优先级任务剥夺，不可重入型函数中的数据可能会被破坏。
3）若一个函数是可重入的，则该函数必须满足以下必要条件： 
    i.不能含有静态（全局）非常量数据。
	ii.不能返回静态（全局）非常量数据的地址。 
	iii.只能处理由调用者提供的数据。
2.那些时候不允许内核抢占呢？
	1）内核正在进行中断处理。在Linux内核中不能抢占中断（中断只能被其他中断中止和抢占，进程不能中止和抢占中断，内核抢占是被进程抢占和中止），在中断例程中不允许
	进行进程调度。进程调度函数schedule()会对此做出判断，如果是在中断中调用，会打印错误。
    2）内核正在进行中断上下文的下半部处理时，硬件中断返回前会执行软中断，此时仍然处于中断上下文中，所以此时无法进行内核抢占。
    3）内核的代码段正持有自旋锁（spinlock）、读写锁（writelock/readlock）时，内核代码段处于锁保护状态。此时，内核不能被抢占，否则由于抢占将导致其他CPU长期不能
	获得锁而出现死锁状态。
	4）内核正在对每CPU私有的数据结构（Per-CPU data structures）进行操作。在SMP（对称多处理器）中，对于每CPU数据结构并未采用自旋锁进行保护，因为这些数据结构隐含
	地被保护了（不同的CPU上有不同的每CPU数据，其他CPU上运行的进程不能访问另一个CPU的每CPU数据）。在这种情况下，虽然并未采用锁机制，同样不能进行内核抢占，因为如
	果允许内核抢占，一个进程被抢占后重新调度，有可能调度到其他的CPU上去，这时定义的每CPU数据变量就会发生错位。因此，对于每CPU数据访问时，同样也无法进行内核抢占。
3.抢占发生时机：
    1）当一个中断处理例程退出，在返回到内核态时，此时隐式调用schedule()函数，当前任务没有主动放弃CPU使用权，而是被剥夺了CPU使用权。
	2）当内核代码（程序）从不可抢占状态变为可抢占状态时（preemptible），也就是preempt_count从正数变为0时，此时同样隐式调用schedule()函数。
	3）一个任务在内核态中，显式的调用schedule()函数，任务主动放弃CPU使用权。
	4）一个任务在内核态中被阻塞，导致需要调用schedule()函数，任务主动放弃CPU使用权。
4.同步原语
技术	                     说明	                            适用范围
每CPU变量        	在CPU之间复制数据结构	                     所有CPU         每CPU变量就是为每个CPU构造一个变量的副本，这样多个CPU相互操作各自的副本，互不干涉

原子操作	      对一个计数器原子地“读-修改-写”的指令	         所有CPU         原子操作在Linux内核里分为原子整数操作和原子位操作，针对整数的原子操作只能对atomic_t
                                                                                 类型的数据进行处理，  除了原子整数操作外，内核还提供了一组针对位这一级数据进行操作的
																				 函数，位操作函数是对普通的内在地址进行操作的，它的参数是一个指针和一个位号

内存屏障	             避免指令重新排序      	             本地CPU或所有CPU   优化屏障（optimization barrier）原语保证编译程序不会混淆放在原语操作之前的汇编语言指令
                                                                                和放在原语操作之后的汇编语言指令，这些汇编语言指令在C中都由对应的语句。在Linux中，优化屏障就是
																				barrier()宏。
                                                                                内存屏障（memory barrier）原语确保，在原语之后的操作开始执行之前，原语之前的操作已经完成。因此，
																				内存屏障类似于防火墙，让任何汇编语言指令都不能通过。
																				内存屏障主要有：读屏障、写屏障、通用屏障、优化屏障几种。以读屏障为例，它用于
																				保证读操作有序。屏障之前的读操作一定会先于屏障之后的读操作完成，写操作不受影
																				响，同属于屏障的某一侧的读操作也不受影响。类似的，写屏障用于限制写操作。而通
																				用屏障则对读写操作都有作用。而优化屏障则用于限制编译器的指令重排，不区分读写。
																				前三种屏障都隐含了优化屏障的功能。
																				
自旋锁(spinlock_t)	                加锁时忙等	                 所有CPU        自旋锁（spinlock）是用来在多处理器环境中工作的一种特殊的锁。如果内核控制路径
                                                                               （内核态进程）发现自旋锁“开着”，就获取锁并继续自己的执行。相反，如果内核控制路
																			    径发现锁由运行在另一个CPU上的内核控制路径“锁着”，就在周围“旋转”，反复执行一条
																				紧凑的循环指令，直到锁被释放。
                                                                                自旋锁的循环指令表示“忙等”。即使等待的内核控制路径无事可做（除了浪费时间），
																				它也在CPU上保持运行。不过，自旋锁通常非常方便，因为很多内核资源只锁1毫秒的时
																				间片段，所以说，释放CPU和随后又获得CPU都不会消耗很多时间。
                                                                                一般来说，由自旋锁所保护的每个临界区都是禁止内核抢占的。在单处理器系统上，这
																				种锁本身不起锁的作用，自旋锁原语仅仅是禁止或启用内核抢占。请注意，在自旋锁忙
																				等期间，内核抢占还是有效的，因此，等待自旋锁释放的进程有可能被更高优先级的进
																				程所替代。
																				自旋锁也存在死锁（deadlock）问题。引发这个问题最常见的情况是要求递归使用一
																				个自旋锁，即如果一个已经拥有某个自旋锁的CPU希望第二次获得这个自旋锁，则该
																				CPU将死锁。
																				自旋锁一定是由系统内核调用的。
																				
信号量	                 加锁时阻塞等待	                         所有CPU        信号量，从本质上说，它实现了一个加锁原语，即让等待者睡眠，直到等待的资源变为
                                                                                空闲。实际上，Linux提供两种信号量：
																				内核信号量，由内核控制路径使用。
																				System V IPC信号量，由用户态进程使用。

顺序锁	                 基于访问计数器的锁                   	 所有CPU        这种策略的好处是写者永远不会等待（除非另一个写者正在写），缺点就是有些时候读者
                                                                                不得不反复多次读相同的数据直到它获得有效的副本。
本地中断的禁止	       禁止单个CPU上的中断处理	                 本地CPU        确保一组内核语句被当做一个临界区处理的主要机制之一就是中断禁止
本地软中断的禁止	禁止单个CPU上的可延迟函数处理	             本地CPU        可延迟函数可能在不可预知的时间执行（实际上是在硬件中断程序结束时）。因此，必
                                                                                须保护可延迟函数访问的数据结构使其避免竞争条件。
读-复制-更新（RCU）	通过指针而不是锁来访问共享数据结构	         所有CPU         读-拷贝-更新（RCU）是为了保护在多数情况下被多个CPU读的数据结构而设计的另一种
                                                                                 同步技术。RCU允许多个读者和写者并发执行（相对于只允许一个写者执行的顺序锁有
																				 了改进）。而且，RCU是不是用锁的，就是说，它不使用被所有CPU共享的锁或计数器，
																				 在这一点上与读写自旋锁和顺序锁相比，RCU具有更大的优势。       


5.读写自旋锁
将线程区分为读者和写者、多个读者允许同时访问共享资源、申请线程在等待期内依然使用忙等待方式的锁，我们称之为读写自旋锁（Reader-Writer Spinlock）。

6.各类同步原语实现原理
	1）原子操作--atomict_t类型和原子位
		操作码前缀是lock字节（0xf0）的“读-修改-写”汇编语言指令，即使在多处理器操作系统中也是原子的。当控制单元检测到这个前缀时，就“锁定”内存总线，直到这条指令执行完成为止。
	2）屏障--优化屏障和内存屏障
		barrier()和volatile：禁止编译器把asm指令与程序中的其他指令重新组合；
	    内存屏障：在原语之后的操作开始执行之前，原语之前的操作已完成。
	3）锁
	在cmpxchg执行期间，锁住内存地址[edx]，其他处理器不能访问该内存，保证原子性。即使是在32位机器上修改64位的内存也可以保证原子性。将本处理器上写缓存全部强制写回主存中去，也就是写屏障
，保证每个线程的本地内存与主存一致。禁止cmpxchg与前后任何指令重排序，防止指令重排序。
内核态和用户态的混合机制。还没有futex的时候，内核是如何维护同步与互斥的呢？系统内核维护一个对象，这个对象对所有进程可见，这个对象是用来管理互斥锁并且通知阻塞的进程。如果进程A要进入临界区，
先去内核查看这个对象，有没有别的进程在占用这个临界区，出临界区的时候，也去内核查看这个对象，有没有别的进程在等待进入临界区。
	互斥锁
	1、互斥锁的结构？
	在futex的基础上用的内存共享变量来实现的。
	2、不能锁住的时候，是如何进入休眠，又如何等待被唤醒的呢？
	进入锁的时候就会区检查那个共享变量，如果不能获取锁，就会通过futex系统调用进入休眠。如果有人释放锁，就会通过futex来唤醒。	

7.原子操作的核心	
	它的实现核心是lock指令，而对于单CPU系统来说，则退化为空操作，因为对于单CPU来说，在某程序执行期间，不可能有其它CPU来中断它的执行，因此，实际上，非SMP系统中的原子操作是没有必要存在
的。下面讨论SMP系统。讨论前，先了解x86中的lock指令。lock指令是一种前缀，它可与其他指令联合，用来维持总线的锁存信号直到与其联合的指令执行完为止。当CPU与其他处理机协同工作时，该指令可避
免破坏有用信息。它对中断没有任何影响，因为中断只能在指令之间产生。lock前缀的真正作用是保持对系统总线的控制，直到整条指令执行完毕。

8.自旋锁的实现核心
	对于单CPU来说，它的机制实际上就是禁止和使能抢占，对于CPU存在内核抢占机制的，将禁止内核抢占，否则，退化为空操作。由于slock只有高8位用于保证顺序性，所以这段源码最大只支持256个处理器
同时申请自旋锁。

9.内存屏障实现核心
	Memory Barrier是指编译器和处理器对代码进行优化(对读写指令进行重新排序)后，导致对内存的写入操作不能及时的反应到读操作中（锁机制无法保证时序正确）。
实现的核心其实是依靠如下指令：1.lock指令（已在第一部分中提及）；2.lfence指令：停止相关流水线，直到lfence之前对内存进行读取操作的指令全部完成；3.sfence指令：停止相关流水线，直到sfence
之前对内存进行写入操作的指令全部完成；4.mfence指令：停止相关流水线，直到mfence之前对内存进行读取和写入操作的指令全部完成。

10.读写锁实现核心
	假如现在有进程P1向操作系统申请了读写自旋锁，设读写锁变量A已经被定义，它的初值为RW_LOCK_UNLOCKED(0x01000000)。配合图4.2，图4.3所示的源码内容，若此时进程P1对它申请读锁操作，则
read_lock()对读写锁变量A减1，如果相减后A的值结果为负，则说明此时系统中已经有某个进程（设为P2）对这个读写锁变量使用写锁函数write_lock()上锁，这时候系统便会持续等待P2对写锁的释放，持续
等待过程的源码实现如图4.5所示。假如进程P1读锁申请成功，若P1在使用读锁过程中，存在另一个进程P3申请写锁操作。此时write_lock()对读写锁变量A减0x01000000并判断，如果结果非零，则说明此时锁
变量A已被write_lock()函数上锁或用read_lock()函数上锁，进而便跳转到图4.6所示的写锁失败的汇编函数，持续等待锁变量A被进程P1释放。
	可以看出解锁函数中的实现其实简单的加1和减1操作

11.信号量实现核心
	从源码中可以看到信号量利用自旋锁的相关函数实现了对count变量的保护，通过判断变量是否大于0以及自增减来实现信号量的申请和释放。也是因为这一点，所以信号量能够实现同步机制。关于信号量
的内容还有一点需要提及，我们知道信号量时进程级的，因此对于它的使用必然是当占用资源较长时间的时候。这点在使用信号量的使用需要重点考虑，反之，则容易影响程序的性能等。
	


























